{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61918792",
   "metadata": {},
   "source": [
    "## Neural net zelf bouwen - practicum week 2 / periode 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1bed2d",
   "metadata": {},
   "source": [
    "In dit notebook documenteer ik de stappen die ik heb gemaakt mbt het zelf implementeren van een neural net. Ik heb voor een notebook gekozen omdat ik hierin de code beter kan onderverdelen en zo mijn stappen/progressie kan bijhouden. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14cc46f6",
   "metadata": {},
   "source": [
    "De opdracht is het implementeren van een neuraal netwerk dat kruisjes van rondjes kan onderscheiden in een 3 x 3 pixels rooster/scherm. Elke pixel kan dus zwart zijn (waarde is dan 1) of wit (waarde is dan 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1b5c373",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51571912",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#Een cirkel ziet er dus zo uit:\n",
    "\n",
    "cirkel = [\n",
    "    [1,1,1],\n",
    "    [1,0,1],\n",
    "    [1,1,1]\n",
    "]\n",
    "\n",
    "#Een kruis ziet er zo uit:\n",
    "\n",
    "kruis = [\n",
    "    [0,1,0],\n",
    "    [1,1,1],\n",
    "    [0,1,0]\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df74fa3b",
   "metadata": {},
   "source": [
    "Voor nu werk ik enkel met deze twee vormen. Natuurlijk kunnen de negatieven van de bovenstaande matrices ook een kruis/cirkel vormen (maar dan wit van kleur). Daarnaast kan er ook nog een schuin kruis worden gemaakt, maar ook dat laat ik voor nu even links liggen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d544fdf3",
   "metadata": {},
   "source": [
    "## Input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7ceba1",
   "metadata": {},
   "source": [
    "Als input krijgen we dus matrices van 3 x 3. Elk vakje in deze matrix is dus een input in onze inputlaag van totaal 9 neuronen. \n",
    "\n",
    "Om te beginnen ga ik voor één enkele neuron de implementatiestappen doorlopen, om dit later uit te breiden naar een heel netwerk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c978d75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1], [1], [1], [1], [0], [1], [1], [1], [1]]\n"
     ]
    }
   ],
   "source": [
    "#De input komt binnen als 3x3 matrix - voor de eenvoud maken we hier een 9x1 vector van:\n",
    "\n",
    "def transpose_vec(input_vec):\n",
    "    flat_array = []\n",
    "    for i in input_vec:\n",
    "        for n in i:\n",
    "            flat_array.append([n])\n",
    "    return flat_array\n",
    "\n",
    "#Voorbeeld voor hoe dit met een cirkel matrix gaat:\n",
    "cirkel_vector = transpose_vec(cirkel)\n",
    "\n",
    "print(cirkel_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc97d1f",
   "metadata": {},
   "source": [
    "Hierboven staat dus input vector die we aan onze 1-cellige NN voeden. \n",
    "\n",
    "Vanuit elke input neuron loopt er (in een fully connected netwerk) een weight(lijn) naar elke neuron in de volgende laag (in dit simpele geval direct naar de output laag).\n",
    "\n",
    "Om tot een output te komen vermenigvuldigen we de input van de input neuron met diens weight. Als we dit voor alle inputs en weights doen, per neuron in de volgende laag, is de output de gewogen som van alle vermenigvuldigingen. Hierbij tellen we de zogenaamde bias bij op. Het resultaat stoppen we vervolgens in een activatie functie, en dit geeft ons de output voor de neuron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd060c91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.34], [0.88], [0.09], [0.34], [0.08], [0.83], [0.75], [0.39], [0.13]]\n"
     ]
    }
   ],
   "source": [
    "#We initialiseren de weights voor onze neuron. Dit zijn er in ons geval 9.\n",
    "\n",
    "def init_weights(size):\n",
    "    return [[round(random.uniform(0, 1), 2)] for i in range(size)]\n",
    "\n",
    "#Elke input neuron (van de 9) heeft een weight, dus het aantal weights is gelijk aan het aantal input neurons:\n",
    "\n",
    "weights_voorbeeld = init_weights(len(cirkel_vector))\n",
    "print(weights_voorbeeld)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929321ba",
   "metadata": {},
   "source": [
    "Ook de bias zullen we random initialiseren, dit is maar één getal aangezien elke neuron één bias heeft. In een netwerk is de bias een vector met daarin voor elke neuron uit de laag een bias waarde. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cea9c69d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2\n"
     ]
    }
   ],
   "source": [
    "def init_bias():\n",
    "\n",
    "    return round(random.uniform(0, 1), 2)\n",
    "\n",
    "bias_voorbeeld = init_bias()\n",
    "print(bias_voorbeeld)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff64381",
   "metadata": {},
   "source": [
    "We hebben dus nu voor één neuron de volgende waardes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b8fe93ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input vector is [[1], [1], [1], [1], [0], [1], [1], [1], [1]]\n",
      "Weight vector is [[0.34], [0.88], [0.09], [0.34], [0.08], [0.83], [0.75], [0.39], [0.13]]\n",
      "Bias is 0.2\n"
     ]
    }
   ],
   "source": [
    "print(f\"Input vector is {cirkel_vector}\")\n",
    "print(f\"Weight vector is {weights_voorbeeld}\")\n",
    "print(f\"Bias is {bias_voorbeeld}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a2e422",
   "metadata": {},
   "source": [
    "Nu is het een kwestie van elke waarde in de input vector vermenigvuldigen met de corresponderende weight. Hiervan nemen we de som. De bias tellen we hierbij op, en dat is onze voorlopige output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea34fd77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functie om een vector vlak te maken (dus een enkele list ipv een list of lists)\n",
    "def flatten_matrix(input_vec):\n",
    "    \n",
    "    return [i for subl in input_vec for i in subl]\n",
    "\n",
    "\n",
    "\n",
    "#Functie om de output te krijgen\n",
    "def get_output(input_vec, weight_vec, bias):\n",
    "    \n",
    "    zipped_l = list(zip(flatten_matrix(input_vec), flatten_matrix(weight_vec)))\n",
    "    \n",
    "    return sum([i[0]*i[1] for i in zipped_l]) + bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e95cd6a",
   "metadata": {},
   "source": [
    "We kunnen, als we nog even niet op de activatie functie inzoomen, dus de output van onze neuron berekenen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9991cae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.95\n"
     ]
    }
   ],
   "source": [
    "print(get_output(cirkel_vector, weights_voorbeeld, bias_voorbeeld))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a12f309",
   "metadata": {},
   "source": [
    "## Meerdere neuronen / een laag implementeren"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498528f5",
   "metadata": {},
   "source": [
    "Hierboven hebben we gewerkt met een enkele neuron. Het is nu zaak om te kijken of we een 'layer' van meerdere neuronen kunnen maken en de output hiervan kunnen genereren.\n",
    "\n",
    "Dit is niets meer dan de bovenstaande stappen volgen voor meerdere setjes weights (per neuron) en biases (per neuron). In dit geval gaan we naar een layer van 2 output neuronen (dus nog geen hidden layer). \n",
    "\n",
    "We beginnen met de weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0d0f7c6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.38, 0.81, 0.96, 0.98, 0.56, 0.44, 0.82, 0.66, 0.94], [0.95, 0.17, 0.12, 0.33, 0.36, 0.89, 0.27, 0.32, 0.55]]\n",
      "[0.68, 0.63]\n"
     ]
    }
   ],
   "source": [
    "#We maken voor elke output neuron een set weights. In dit geval dus twee, maar stel dat we 4 of 5 neuronen willen\n",
    "#zouden we ook meerdere setjes weights/bias kunnen maken\n",
    "\n",
    "weights_1 = init_weights(len(cirkel_vector))\n",
    "weights_2 = init_weights(len(cirkel_vector))\n",
    "\n",
    "weight_list = [flatten_matrix(weights_1), flatten_matrix(weights_2)]\n",
    "\n",
    "#Voor elke neuron maken we ook een bias\n",
    "\n",
    "bias_1 = init_bias()\n",
    "bias_2 = init_bias()\n",
    "\n",
    "bias_list = [bias_1, bias_2]\n",
    "\n",
    "print(weight_list)\n",
    "print(bias_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9578578a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We zippen de weights en biases waardoor we een lijst hebben van tuples, waarbij elke tuple onze weights en bias bevat)\n",
    "\n",
    "w_and_b = list(zip(weight_list, bias_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d18695f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights: [0.38, 0.81, 0.96, 0.98, 0.56, 0.44, 0.82, 0.66, 0.94], bias: 0.68\n",
      "Weights: [0.95, 0.17, 0.12, 0.33, 0.36, 0.89, 0.27, 0.32, 0.55], bias: 0.63\n"
     ]
    }
   ],
   "source": [
    "for w, b in w_and_b:\n",
    "    print(f'Weights: {w}, bias: {b}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b100e90",
   "metadata": {},
   "source": [
    "De lijst hierboven geeft dus een lijst van tuples, met in elke tuple (elke neuron) de weights en bias.\n",
    "\n",
    "Hieronder staat een functie die dus één forward pass afwerkt, met als output de 2x1 vector. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "25f8220e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_pass(input_m, w_and_b):\n",
    "    print(f\"input_matrix is {input_m}\")\n",
    "    \n",
    "    network_output = []\n",
    "    \n",
    "    for weights, bias in w_and_b:\n",
    "        neuron_output = 0\n",
    "        print(f\"Weights of neuron: {weights}\")\n",
    "        print(f\"Bias of neuron: {bias}\")\n",
    "        \n",
    "        for w, v in zip(flatten_matrix(input_m), weights):\n",
    "            print(f\"Adding {w} times {v} to weighted_sum\")\n",
    "            neuron_output += (w*v)\n",
    "            print(f\"Weighted sum is now {neuron_output}\")\n",
    "        print(f\"Adding bias of {bias} to weighted sum {neuron_output}\")\n",
    "        \n",
    "        neuron_output += bias \n",
    "        network_output.append(neuron_output)\n",
    "        print(f\"Total neuron output is now {neuron_output}\")\n",
    "        \n",
    "    return network_output\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2b350191",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_matrix is [[1], [1], [1], [1], [0], [1], [1], [1], [1]]\n",
      "Weights of neuron: [0.38, 0.81, 0.96, 0.98, 0.56, 0.44, 0.82, 0.66, 0.94]\n",
      "Bias of neuron: 0.68\n",
      "Adding 1 times 0.38 to weighted_sum\n",
      "Weighted sum is now 0.38\n",
      "Adding 1 times 0.81 to weighted_sum\n",
      "Weighted sum is now 1.19\n",
      "Adding 1 times 0.96 to weighted_sum\n",
      "Weighted sum is now 2.15\n",
      "Adding 1 times 0.98 to weighted_sum\n",
      "Weighted sum is now 3.13\n",
      "Adding 0 times 0.56 to weighted_sum\n",
      "Weighted sum is now 3.13\n",
      "Adding 1 times 0.44 to weighted_sum\n",
      "Weighted sum is now 3.57\n",
      "Adding 1 times 0.82 to weighted_sum\n",
      "Weighted sum is now 4.39\n",
      "Adding 1 times 0.66 to weighted_sum\n",
      "Weighted sum is now 5.05\n",
      "Adding 1 times 0.94 to weighted_sum\n",
      "Weighted sum is now 5.99\n",
      "Adding bias of 0.68 to weighted sum 5.99\n",
      "Total neuron output is now 6.67\n",
      "Weights of neuron: [0.95, 0.17, 0.12, 0.33, 0.36, 0.89, 0.27, 0.32, 0.55]\n",
      "Bias of neuron: 0.63\n",
      "Adding 1 times 0.95 to weighted_sum\n",
      "Weighted sum is now 0.95\n",
      "Adding 1 times 0.17 to weighted_sum\n",
      "Weighted sum is now 1.1199999999999999\n",
      "Adding 1 times 0.12 to weighted_sum\n",
      "Weighted sum is now 1.2399999999999998\n",
      "Adding 1 times 0.33 to weighted_sum\n",
      "Weighted sum is now 1.5699999999999998\n",
      "Adding 0 times 0.36 to weighted_sum\n",
      "Weighted sum is now 1.5699999999999998\n",
      "Adding 1 times 0.89 to weighted_sum\n",
      "Weighted sum is now 2.46\n",
      "Adding 1 times 0.27 to weighted_sum\n",
      "Weighted sum is now 2.73\n",
      "Adding 1 times 0.32 to weighted_sum\n",
      "Weighted sum is now 3.05\n",
      "Adding 1 times 0.55 to weighted_sum\n",
      "Weighted sum is now 3.5999999999999996\n",
      "Adding bias of 0.63 to weighted sum 3.5999999999999996\n",
      "Total neuron output is now 4.2299999999999995\n"
     ]
    }
   ],
   "source": [
    "nn_outputs = forward_pass(cirkel_vector, w_and_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d12d4a87",
   "metadata": {},
   "source": [
    "Met de bovenstaande code kunnen we dus een enkel-laags neuraal netwerk maken waarbij de output vector de waardes van de output laag geeft, en waarvan de lengte afhankelijk is van het aantal setjes weights en biases die we er in stoppen. Aangezien de enkele (output) laag uit twee neuronen bestaat verwachten we een vector van 2 x 1 als output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "32076bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.67, 4.2299999999999995]\n"
     ]
    }
   ],
   "source": [
    "print(nn_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "85802a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checken of de numpy .dot methode dezelfde output geeft, en dat is zo. De handmatige manier werkt dus voor \n",
    "# dit netwerk met 1 laag.\n",
    "\n",
    "x_o = np.dot(weight_list, flatten_matrix(cirkel_vector)) + bias_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ddf1392e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.67 4.23]\n"
     ]
    }
   ],
   "source": [
    "print(x_o)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093b269f",
   "metadata": {},
   "source": [
    "Als laatste stap moeten we de output door een activatie functie halen, en in dit geval (waarbij er geen hidden layers in het netwerk bestaan, en we dus enkel de output layer hebben) is dat de softmax activatie functie. De softmax functie maakt van de \"input\" een verdeling met een totaal van 1, een waarschijnlijkheidsdistributie dus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0faa652e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(vector):\n",
    "    e = 2.71828\n",
    "    output_vec = []\n",
    "    vec = [e**a for a in vector]\n",
    "    vec_sum = sum(vec)\n",
    "    \n",
    "    for n in vec:\n",
    "        output_vec.append(n/vec_sum)\n",
    "    \n",
    "    return output_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8e4405ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9198269667910991, 0.08017303320890098]\n"
     ]
    }
   ],
   "source": [
    "print(softmax(nn_outputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a93655d",
   "metadata": {},
   "source": [
    "De bovenstaande output vector geeft ons dus de waarschijnlijkheid van de mogelijke uitkomsten, namelijk een kruis en een rondje. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c92c6bc",
   "metadata": {},
   "source": [
    "## Een class maken voor een layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d275a097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 0, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "input_voorbeeld = flatten_matrix(cirkel)\n",
    "\n",
    "print(input_voorbeeld)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96ea4dfb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'flatten_matrix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m layer_input \u001b[38;5;241m=\u001b[39m \u001b[43mflatten_matrix\u001b[49m(cirkel)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#Class aanmaken\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mLayer\u001b[39;00m:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'flatten_matrix' is not defined"
     ]
    }
   ],
   "source": [
    "layer_input = flatten_matrix(cirkel)\n",
    "\n",
    "#Class aanmaken\n",
    "class Layer:\n",
    "    \n",
    "    def __init__(self, neuron_amount, input_shape): # Aantal neuronen in de laag en het aa\n",
    "        self.weights = np.random.randn(input_shape, neuron_amount) # We initialiseren de weight matrix\n",
    "        self.biases = np.zeros((1, neuron_amount)) #biases zetten we op 0\n",
    "        \n",
    "    def forward_pass(self, inputs):\n",
    "        \n",
    "        self.output = np.dot(inputs, self.weights) + self.biases\n",
    "        \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6fdfbf24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1570eeb8",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (3066990509.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[31], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    print(lay_1.forward_pass(())\u001b[0m\n\u001b[0m                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f457eaa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
